{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2. Ingesting Data into the Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머 / CloudΨ - DS on GCP [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 차례 \n",
    "* 준비단계    \n",
    "* Airline On-Time Perfomance Data\n",
    "    * Knowability\n",
    "    * Training–Serving Skew\n",
    "    * Download Procedure\n",
    "    * Dataset Attributes\n",
    "* Why Not Store the Data in Situ?\n",
    "    * Scaling Up\n",
    "    * Scaling Out\n",
    "    * Data in Situ with Colossus and Jupiter\n",
    "* Ingesting Data\n",
    "    * Reverse Engineering a Web Form\n",
    "    * Dataset Download\n",
    "    * Exploration and Cleanup\n",
    "    * Uploading Data to Google Cloud Storage\n",
    "* Scheduling Monthly Downloads\n",
    "    * Ingesting in Python\n",
    "    * Flask Web App\n",
    "    * Running on App Engine\n",
    "    * Securing the URL\n",
    "    * Scheduling a Cron Task\n",
    "* Summary\n",
    "* Code Break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고 \n",
    "* Getting started with Google Cloud Training Material - 2018 - https://www.slideshare.net/jkbaseer/getting-started-with-google-cloud-training-material-2018\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/cloudonboardtrainingmanual2018sg17april2018-180417132701/95/getting-started-with-google-cloud-training-material-2018-17-1024.jpg?cb=1523971737\" width=800 />\n",
    "<img src=\"https://image.slidesharecdn.com/cloudonboardtrainingmanual2018sg17april2018-180417132701/95/getting-started-with-google-cloud-training-material-2018-18-1024.jpg?cb=1523971737\" width=800 />\n",
    "<img src=\"https://image.slidesharecdn.com/cloudonboardtrainingmanual2018sg17april2018-180417132701/95/getting-started-with-google-cloud-training-material-2018-20-1024.jpg?cb=1523971737\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1. - probabilistic decision criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../ch01/figures/cap02.png\" width=600 />\n",
    "<img src=\"../ch01/figures/cap03.png\" width=600 />\n",
    "<img src=\"../ch01/figures/cap04.png\" width=600 />\n",
    "<img src=\"../ch01/figures/cap05.png\" width=600 />\n",
    "<img src=\"../ch01/figures/cap06.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 준비단계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* US Bureau of Transportation Statistics (BTS) \n",
    "    - https://www.transtats.bts.gov/\n",
    "    - 미국 교통 통계국\n",
    "    - 1987년 이후부터 여러 항공편의 과거이력 데이터가 있다. \n",
    "    - <font color=\"red\">Airline On-Time Performance Data</font>\n",
    "        - 정시 도착 퍼포먼스 데이터이므로, \n",
    "        - 비행 지연에 대한 정보를 포함한다.\n",
    "        - 이 책에서는 이걸 쓸 것이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02_Ingesting_Data_into_the_Cloud.ipynb \u001b[34mfigures\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                \u001b[31mingest_from_crsbucket.sh\u001b[m\u001b[m \u001b[31mupload.sh\u001b[m\u001b[m\r\n",
      "\u001b[31mdownload.sh\u001b[m\u001b[m              \u001b[34mmonthlyupdate\u001b[m\u001b[m            \u001b[31mzip_to_csv.sh\u001b[m\u001b[m\r\n",
      "\u001b[31mingest.sh\u001b[m\u001b[m                \u001b[31mquotes_comma.sh\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data-science-on-gcp/02_ingest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../data-science-on-gcp/02_ingest/download.sh ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02_Ingesting_Data_into_the_Cloud.ipynb \u001b[34mfigures\u001b[m\u001b[m\r\n",
      "\u001b[31mdownload.sh\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복사한 download.sh 파일의 다음 부분을"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "\r\n",
      "export YEAR=${YEAR:=2015}\r\n",
      "echo \"Downloading YEAR=$YEAR...\"\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 download.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {YEAR:=2015}를 {YEAR:=2018}로 바꿔서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "\r\n",
      "export YEAR=${YEAR:=2018}\r\n",
      "echo \"Downloading YEAR=$YEAR...\"\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 download.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크립트를 실행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading YEAR=2018...\n",
      "201801\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  5405  100   191  100  5214     10    299  0:00:19  0:00:17  0:00:02    44--:--  2472\n",
      "Received <head><title>Object moved</title></head>\n",
      "<body><h1>Object Moved</h1>This object may be found <a HREF=\"https://transtats.bts.gov/ftproot/TranStatsData/137304439_T_ONTIME.zip\">here</a>.</body>\n",
      "https://transtats.bts.gov/ftproot/TranStatsData/137304439_T_ONTIME.zip\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 18.3M  100 18.3M    0     0   140k      0  0:02:14  0:02:14 --:--:--  112k  0:00:14  0:01:57  223k 0:02:20  0:01:03  0:01:17  101k01:31  0:00:47  100k\n",
      "201802\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  5405  100   191  100  5214     11    320  0:00:17  0:00:16  0:00:01    47\n",
      "Received <head><title>Object moved</title></head>\n",
      "<body><h1>Object Moved</h1>This object may be found <a HREF=\"https://transtats.bts.gov/ftproot/TranStatsData/137304555_T_ONTIME.zip\">here</a>.</body>\n",
      "https://transtats.bts.gov/ftproot/TranStatsData/137304555_T_ONTIME.zip\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      " 48 16.8M   48 8342k    0     0   143k      0  0:02:00  0:00:58  0:01:02  212k^C\n"
     ]
    }
   ],
   "source": [
    "!sh download.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02_Ingesting_Data_into_the_Cloud.ipynb \u001b[31mdownload.sh\u001b[m\u001b[m\r\n",
      "201801.zip                             \u001b[34mfigures\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                \u001b[31mingest_from_crsbucket.sh\u001b[m\u001b[m \u001b[31mupload.sh\u001b[m\u001b[m\r\n",
      "\u001b[31mdownload.sh\u001b[m\u001b[m              \u001b[34mmonthlyupdate\u001b[m\u001b[m            \u001b[31mzip_to_csv.sh\u001b[m\u001b[m\r\n",
      "\u001b[31mingest.sh\u001b[m\u001b[m                \u001b[31mquotes_comma.sh\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data-science-on-gcp/02_ingest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../data-science-on-gcp/02_ingest/zip_to_csv.sh ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02_Ingesting_Data_into_the_Cloud.ipynb \u001b[34mfigures\u001b[m\u001b[m\r\n",
      "201801.zip                             \u001b[31mzip_to_csv.sh\u001b[m\u001b[m\r\n",
      "\u001b[31mdownload.sh\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복사한 zip_to_csv.sh 파일의 다음 부분을"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "echo ${YEAR:=2015}  # default if YEAR not set\r\n",
      "for month in `seq -w 1 12`; do \r\n",
      "   unzip $YEAR$month.zip\r\n",
      "   mv *ONTIME.csv $YEAR$month.csv\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 zip_to_csv.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {YEAR:=2015}를 {YEAR:=2018}로 바꿔서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "echo ${YEAR:=2018}  # default if YEAR not set\r\n",
      "for month in `seq -w 1 12`; do \r\n",
      "   unzip $YEAR$month.zip\r\n",
      "   mv *ONTIME.csv $YEAR$month.csv\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 zip_to_csv.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크립트를 실행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "Archive:  201801.zip\n",
      "  inflating: 137304439_T_ONTIME.csv  \n",
      "Archive:  201802.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of 201802.zip or\n",
      "        201802.zip.zip, and cannot find 201802.zip.ZIP, period.\n",
      "mv: rename *ONTIME.csv to 201802.csv: No such file or directory\n",
      "unzip:  cannot find or open 201803.zip, 201803.zip.zip or 201803.zip.ZIP.\n",
      "mv: rename *ONTIME.csv to 201803.csv: No such file or directory\n",
      "rm: 201803.zip: No such file or directory\n",
      "unzip:  cannot find or open 201804.zip, 201804.zip.zip or 201804.zip.ZIP.\n",
      "mv: rename *ONTIME.csv to 201804.csv: No such file or directory\n",
      "rm: 201804.zip: No such file or directory\n",
      "unzip:  cannot find or open 201805.zip, 201805.zip.zip or 201805.zip.ZIP.\n",
      "mv: rename *ONTIME.csv to 201805.csv: No such file or directory\n",
      "rm: 201805.zip: No such file or directory\n",
      "unzip:  cannot find or open 201806.zip, 201806.zip.zip or 201806.zip.ZIP.\n",
      "mv: rename *ONTIME.csv to 201806.csv: No such file or directory\n",
      "rm: 201806.zip: No such file or directory\n",
      "unzip:  cannot find or open 201807.zip, 201807.zip.zip or 201807.zip.ZIP.\n",
      "mv: rename *ONTIME.csv to 201807.csv: No such file or directory\n",
      "rm: 201807.zip: No such file or directory\n",
      "unzip:  cannot find or open 201808.zip, 201808.zip.zip or 201808.zip.ZIP.\n",
      "mv: rename *ONTIME.csv to 201808.csv: No such file or directory\n",
      "rm: 201808.zip: No such file or directory\n",
      "unzip:  cannot find or open 201809.zip, 201809.zip.zip or 201809.zip.ZIP.\n",
      "mv: rename *ONTIME.csv to 201809.csv: No such file or directory\n",
      "rm: 201809.zip: No such file or directory\n",
      "unzip:  cannot find or open 201810.zip, 201810.zip.zip or 201810.zip.ZIP.\n",
      "mv: rename *ONTIME.csv to 201810.csv: No such file or directory\n",
      "rm: 201810.zip: No such file or directory\n",
      "unzip:  cannot find or open 201811.zip, 201811.zip.zip or 201811.zip.ZIP.\n",
      "mv: rename *ONTIME.csv to 201811.csv: No such file or directory\n",
      "rm: 201811.zip: No such file or directory\n",
      "unzip:  cannot find or open 201812.zip, 201812.zip.zip or 201812.zip.ZIP.\n",
      "mv: rename *ONTIME.csv to 201812.csv: No such file or directory\n",
      "rm: 201812.zip: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!sh zip_to_csv.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02_Ingesting_Data_into_the_Cloud.ipynb \u001b[34mfigures\u001b[m\u001b[m\r\n",
      "201801.csv                             \u001b[31mzip_to_csv.sh\u001b[m\u001b[m\r\n",
      "\u001b[31mdownload.sh\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FL_DATE\",\"UNIQUE_CARRIER\",\"AIRLINE_ID\",\"CARRIER\",\"FL_NUM\",\"ORIGIN_AIRPORT_ID\",\"ORIGIN_AIRPORT_SEQ_ID\",\"ORIGIN_CITY_MARKET_ID\",\"ORIGIN\",\"DEST_AIRPORT_ID\",\"DEST_AIRPORT_SEQ_ID\",\"DEST_CITY_MARKET_ID\",\"DEST\",\"CRS_DEP_TIME\",\"DEP_TIME\",\"DEP_DELAY\",\"TAXI_OUT\",\"WHEELS_OFF\",\"WHEELS_ON\",\"TAXI_IN\",\"CRS_ARR_TIME\",\"ARR_TIME\",\"ARR_DELAY\",\"CANCELLED\",\"CANCELLATION_CODE\",\"DIVERTED\",\"DISTANCE\",\r\n",
      "2018-01-01,\"UA\",19977,\"UA\",\"2429\",11618,1161802,31703,\"EWR\",11292,1129202,30325,\"DEN\",\"1517\",\"1512\",-5.00,15.00,\"1527\",\"1712\",10.00,\"1745\",\"1722\",-23.00,0.00,\"\",0.00,1605.00,\r\n",
      "2018-01-01,\"UA\",19977,\"UA\",\"2427\",12889,1288903,32211,\"LAS\",14771,1477104,32457,\"SFO\",\"1115\",\"1107\",-8.00,11.00,\"1118\",\"1223\",7.00,\"1254\",\"1230\",-24.00,0.00,\"\",0.00,414.00,\r\n",
      "2018-01-01,\"UA\",19977,\"UA\",\"2426\",14908,1490803,32575,\"SNA\",11292,1129202,30325,\"DEN\",\"1335\",\"1330\",-5.00,15.00,\"1345\",\"1631\",5.00,\"1649\",\"1636\",-13.00,0.00,\"\",0.00,846.00,\r\n",
      "2018-01-01,\"UA\",19977,\"UA\",\"2425\",14635,1463502,31714,\"RSW\",13930,1393006,30977,\"ORD\",\"1546\",\"1552\",6.00,19.00,\"1611\",\"1748\",6.00,\"1756\",\"1754\",-2.00,0.00,\"\",0.00,1120.00,\r\n",
      "2018-01-01,\"UA\",19977,\"UA\",\"2424\",13930,1393006,30977,\"ORD\",10257,1025702,30257,\"ALB\",\"0630\",\"0650\",20.00,13.00,\"0703\",\"0926\",10.00,\"0922\",\"0936\",14.00,0.00,\"\",0.00,723.00,\r\n",
      "2018-01-01,\"UA\",19977,\"UA\",\"2422\",13930,1393006,30977,\"ORD\",13871,1387102,33316,\"OMA\",\"2241\",\"2244\",3.00,15.00,\"2259\",\"0001\",2.00,\"0014\",\"0003\",-11.00,0.00,\"\",0.00,416.00,\r\n",
      "2018-01-01,\"UA\",19977,\"UA\",\"2421\",12266,1226603,31453,\"IAH\",12889,1288903,32211,\"LAS\",\"0750\",\"0747\",-3.00,14.00,\"0801\",\"0854\",6.00,\"0916\",\"0900\",-16.00,0.00,\"\",0.00,1222.00,\r\n",
      "2018-01-01,\"UA\",19977,\"UA\",\"2420\",11292,1129202,30325,\"DEN\",11003,1100303,31003,\"CID\",\"1324\",\"1318\",-6.00,11.00,\"1329\",\"1554\",6.00,\"1619\",\"1600\",-19.00,0.00,\"\",0.00,692.00,\r\n",
      "2018-01-01,\"UA\",19977,\"UA\",\"2419\",14893,1489302,33192,\"SMF\",11618,1161802,31703,\"EWR\",\"2224\",\"2237\",13.00,10.00,\"2247\",\"0627\",9.00,\"0638\",\"0636\",-2.00,0.00,\"\",0.00,2500.00,\r\n"
     ]
    }
   ],
   "source": [
    "!head 201801.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      27\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 201801.csv  | tail -1 | sed 's/,/ /g' | wc -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  621614 201801.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '201801.csv'\n",
    "d = pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>AIRLINE_ID</th>\n",
       "      <th>CARRIER</th>\n",
       "      <th>FL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>ORIGIN_CITY_MARKET_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_CODE</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>19977</td>\n",
       "      <td>UA</td>\n",
       "      <td>2429</td>\n",
       "      <td>11618</td>\n",
       "      <td>1161802</td>\n",
       "      <td>31703</td>\n",
       "      <td>EWR</td>\n",
       "      <td>11292</td>\n",
       "      <td>...</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1745</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>19977</td>\n",
       "      <td>UA</td>\n",
       "      <td>2427</td>\n",
       "      <td>12889</td>\n",
       "      <td>1288903</td>\n",
       "      <td>32211</td>\n",
       "      <td>LAS</td>\n",
       "      <td>14771</td>\n",
       "      <td>...</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1254</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>19977</td>\n",
       "      <td>UA</td>\n",
       "      <td>2426</td>\n",
       "      <td>14908</td>\n",
       "      <td>1490803</td>\n",
       "      <td>32575</td>\n",
       "      <td>SNA</td>\n",
       "      <td>11292</td>\n",
       "      <td>...</td>\n",
       "      <td>1631.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1649</td>\n",
       "      <td>1636.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>19977</td>\n",
       "      <td>UA</td>\n",
       "      <td>2425</td>\n",
       "      <td>14635</td>\n",
       "      <td>1463502</td>\n",
       "      <td>31714</td>\n",
       "      <td>RSW</td>\n",
       "      <td>13930</td>\n",
       "      <td>...</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1756</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>19977</td>\n",
       "      <td>UA</td>\n",
       "      <td>2424</td>\n",
       "      <td>13930</td>\n",
       "      <td>1393006</td>\n",
       "      <td>30977</td>\n",
       "      <td>ORD</td>\n",
       "      <td>10257</td>\n",
       "      <td>...</td>\n",
       "      <td>926.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>922</td>\n",
       "      <td>936.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FL_DATE UNIQUE_CARRIER  AIRLINE_ID CARRIER  FL_NUM  ORIGIN_AIRPORT_ID  \\\n",
       "0  2018-01-01             UA       19977      UA    2429              11618   \n",
       "1  2018-01-01             UA       19977      UA    2427              12889   \n",
       "2  2018-01-01             UA       19977      UA    2426              14908   \n",
       "3  2018-01-01             UA       19977      UA    2425              14635   \n",
       "4  2018-01-01             UA       19977      UA    2424              13930   \n",
       "\n",
       "   ORIGIN_AIRPORT_SEQ_ID  ORIGIN_CITY_MARKET_ID ORIGIN  DEST_AIRPORT_ID  \\\n",
       "0                1161802                  31703    EWR            11292   \n",
       "1                1288903                  32211    LAS            14771   \n",
       "2                1490803                  32575    SNA            11292   \n",
       "3                1463502                  31714    RSW            13930   \n",
       "4                1393006                  30977    ORD            10257   \n",
       "\n",
       "      ...       WHEELS_ON  TAXI_IN CRS_ARR_TIME  ARR_TIME  ARR_DELAY  \\\n",
       "0     ...          1712.0     10.0         1745    1722.0      -23.0   \n",
       "1     ...          1223.0      7.0         1254    1230.0      -24.0   \n",
       "2     ...          1631.0      5.0         1649    1636.0      -13.0   \n",
       "3     ...          1748.0      6.0         1756    1754.0       -2.0   \n",
       "4     ...           926.0     10.0          922     936.0       14.0   \n",
       "\n",
       "   CANCELLED  CANCELLATION_CODE  DIVERTED  DISTANCE  Unnamed: 27  \n",
       "0        0.0                NaN       0.0    1605.0          NaN  \n",
       "1        0.0                NaN       0.0     414.0          NaN  \n",
       "2        0.0                NaN       0.0     846.0          NaN  \n",
       "3        0.0                NaN       0.0    1120.0          NaN  \n",
       "4        0.0                NaN       0.0     723.0          NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRLINE_ID</th>\n",
       "      <th>FL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>ORIGIN_CITY_MARKET_ID</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>DEST_AIRPORT_SEQ_ID</th>\n",
       "      <th>DEST_CITY_MARKET_ID</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>...</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>621613.000000</td>\n",
       "      <td>621613.000000</td>\n",
       "      <td>621613.000000</td>\n",
       "      <td>6.216130e+05</td>\n",
       "      <td>621613.000000</td>\n",
       "      <td>621613.000000</td>\n",
       "      <td>6.216130e+05</td>\n",
       "      <td>621613.000000</td>\n",
       "      <td>621613.000000</td>\n",
       "      <td>602890.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>601762.000000</td>\n",
       "      <td>601228.000000</td>\n",
       "      <td>601219.000000</td>\n",
       "      <td>621613.000000</td>\n",
       "      <td>602080.000000</td>\n",
       "      <td>600857.000000</td>\n",
       "      <td>621613.000000</td>\n",
       "      <td>621613.000000</td>\n",
       "      <td>621613.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20023.584985</td>\n",
       "      <td>2725.570397</td>\n",
       "      <td>12683.124867</td>\n",
       "      <td>1.268316e+06</td>\n",
       "      <td>31769.210683</td>\n",
       "      <td>12682.911176</td>\n",
       "      <td>1.268295e+06</td>\n",
       "      <td>31769.205091</td>\n",
       "      <td>1326.569938</td>\n",
       "      <td>1333.335882</td>\n",
       "      <td>...</td>\n",
       "      <td>1359.808280</td>\n",
       "      <td>1476.551990</td>\n",
       "      <td>7.490016</td>\n",
       "      <td>1493.005754</td>\n",
       "      <td>1482.041353</td>\n",
       "      <td>3.173973</td>\n",
       "      <td>0.030772</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>761.128849</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>410.893628</td>\n",
       "      <td>1913.261489</td>\n",
       "      <td>1517.027372</td>\n",
       "      <td>1.517025e+05</td>\n",
       "      <td>1306.731354</td>\n",
       "      <td>1516.957095</td>\n",
       "      <td>1.516955e+05</td>\n",
       "      <td>1306.656269</td>\n",
       "      <td>483.627437</td>\n",
       "      <td>493.226616</td>\n",
       "      <td>...</td>\n",
       "      <td>493.039381</td>\n",
       "      <td>514.968248</td>\n",
       "      <td>5.906399</td>\n",
       "      <td>507.466520</td>\n",
       "      <td>518.583014</td>\n",
       "      <td>49.643814</td>\n",
       "      <td>0.172698</td>\n",
       "      <td>0.047522</td>\n",
       "      <td>582.644560</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19393.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10135.000000</td>\n",
       "      <td>1.013505e+06</td>\n",
       "      <td>30070.000000</td>\n",
       "      <td>10135.000000</td>\n",
       "      <td>1.013505e+06</td>\n",
       "      <td>30070.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19790.000000</td>\n",
       "      <td>1044.000000</td>\n",
       "      <td>11292.000000</td>\n",
       "      <td>1.129202e+06</td>\n",
       "      <td>30721.000000</td>\n",
       "      <td>11292.000000</td>\n",
       "      <td>1.129202e+06</td>\n",
       "      <td>30721.000000</td>\n",
       "      <td>916.000000</td>\n",
       "      <td>924.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>941.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1109.000000</td>\n",
       "      <td>1103.000000</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19977.000000</td>\n",
       "      <td>2239.000000</td>\n",
       "      <td>12889.000000</td>\n",
       "      <td>1.288903e+06</td>\n",
       "      <td>31453.000000</td>\n",
       "      <td>12889.000000</td>\n",
       "      <td>1.288903e+06</td>\n",
       "      <td>31453.000000</td>\n",
       "      <td>1320.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1343.000000</td>\n",
       "      <td>1511.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1520.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20378.000000</td>\n",
       "      <td>4444.000000</td>\n",
       "      <td>14057.000000</td>\n",
       "      <td>1.405702e+06</td>\n",
       "      <td>32575.000000</td>\n",
       "      <td>14057.000000</td>\n",
       "      <td>1.405702e+06</td>\n",
       "      <td>32575.000000</td>\n",
       "      <td>1730.000000</td>\n",
       "      <td>1737.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1753.000000</td>\n",
       "      <td>1909.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1914.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21171.000000</td>\n",
       "      <td>9375.000000</td>\n",
       "      <td>16218.000000</td>\n",
       "      <td>1.621801e+06</td>\n",
       "      <td>36133.000000</td>\n",
       "      <td>16218.000000</td>\n",
       "      <td>1.621801e+06</td>\n",
       "      <td>36133.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4983.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AIRLINE_ID         FL_NUM  ORIGIN_AIRPORT_ID  ORIGIN_AIRPORT_SEQ_ID  \\\n",
       "count  621613.000000  621613.000000      621613.000000           6.216130e+05   \n",
       "mean    20023.584985    2725.570397       12683.124867           1.268316e+06   \n",
       "std       410.893628    1913.261489        1517.027372           1.517025e+05   \n",
       "min     19393.000000       1.000000       10135.000000           1.013505e+06   \n",
       "25%     19790.000000    1044.000000       11292.000000           1.129202e+06   \n",
       "50%     19977.000000    2239.000000       12889.000000           1.288903e+06   \n",
       "75%     20378.000000    4444.000000       14057.000000           1.405702e+06   \n",
       "max     21171.000000    9375.000000       16218.000000           1.621801e+06   \n",
       "\n",
       "       ORIGIN_CITY_MARKET_ID  DEST_AIRPORT_ID  DEST_AIRPORT_SEQ_ID  \\\n",
       "count          621613.000000    621613.000000         6.216130e+05   \n",
       "mean            31769.210683     12682.911176         1.268295e+06   \n",
       "std              1306.731354      1516.957095         1.516955e+05   \n",
       "min             30070.000000     10135.000000         1.013505e+06   \n",
       "25%             30721.000000     11292.000000         1.129202e+06   \n",
       "50%             31453.000000     12889.000000         1.288903e+06   \n",
       "75%             32575.000000     14057.000000         1.405702e+06   \n",
       "max             36133.000000     16218.000000         1.621801e+06   \n",
       "\n",
       "       DEST_CITY_MARKET_ID   CRS_DEP_TIME       DEP_TIME     ...       \\\n",
       "count        621613.000000  621613.000000  602890.000000     ...        \n",
       "mean          31769.205091    1326.569938    1333.335882     ...        \n",
       "std            1306.656269     483.627437     493.226616     ...        \n",
       "min           30070.000000       1.000000       1.000000     ...        \n",
       "25%           30721.000000     916.000000     924.000000     ...        \n",
       "50%           31453.000000    1320.000000    1329.000000     ...        \n",
       "75%           32575.000000    1730.000000    1737.000000     ...        \n",
       "max           36133.000000    2359.000000    2400.000000     ...        \n",
       "\n",
       "          WHEELS_OFF      WHEELS_ON        TAXI_IN   CRS_ARR_TIME  \\\n",
       "count  601762.000000  601228.000000  601219.000000  621613.000000   \n",
       "mean     1359.808280    1476.551990       7.490016    1493.005754   \n",
       "std       493.039381     514.968248       5.906399     507.466520   \n",
       "min         1.000000       1.000000       0.000000       1.000000   \n",
       "25%       941.000000    1059.000000       4.000000    1109.000000   \n",
       "50%      1343.000000    1511.000000       6.000000    1520.000000   \n",
       "75%      1753.000000    1909.000000       9.000000    1915.000000   \n",
       "max      2400.000000    2400.000000     258.000000    2359.000000   \n",
       "\n",
       "            ARR_TIME      ARR_DELAY      CANCELLED       DIVERTED  \\\n",
       "count  602080.000000  600857.000000  621613.000000  621613.000000   \n",
       "mean     1482.041353       3.173973       0.030772       0.002263   \n",
       "std       518.583014      49.643814       0.172698       0.047522   \n",
       "min         1.000000   -1290.000000       0.000000       0.000000   \n",
       "25%      1103.000000     -17.000000       0.000000       0.000000   \n",
       "50%      1515.000000      -8.000000       0.000000       0.000000   \n",
       "75%      1914.000000       6.000000       0.000000       0.000000   \n",
       "max      2400.000000    2023.000000       1.000000       1.000000   \n",
       "\n",
       "            DISTANCE  Unnamed: 27  \n",
       "count  621613.000000          0.0  \n",
       "mean      761.128849          NaN  \n",
       "std       582.644560          NaN  \n",
       "min        16.000000          NaN  \n",
       "25%       337.000000          NaN  \n",
       "50%       599.000000          NaN  \n",
       "75%      1005.000000          NaN  \n",
       "max      4983.000000          NaN  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습 1 - Google Cloud Shell 웹 브라우저 콘솔에서 소스 열기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 지난 시간에 GCP 프로젝트를 만들고, 책의 실습 코드가 다운로드되어있다는 가정하에 Google Cloud Shell을 연다\n",
    "    *  https://console.cloud.google.com/\n",
    "    \n",
    "2. Google Cloud Shell 웹 브라우저 콘솔에서 준비단계에서 했던 것들을 직접 해본다.\n",
    "    * 이때 소스 코드들이 있는 data-science-on-gcp 안에\n",
    "    * data라는 디렉토리를 만들고\n",
    "    * data 디렉토리로 이동해서\n",
    "    * 스크립트들을 실행한다 \n",
    "    \n",
    "    예)\n",
    "```shell\n",
    "bash ../02_ingest/download.sh\n",
    "```\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airline On-Time Perfomance Data\n",
    "* Knowability\n",
    "* Training–Serving Skew\n",
    "* Download Procedure\n",
    "* Dataset Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap01.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training–Serving Skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap02.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Not Store the Data in Situ?\n",
    "* Scaling Up\n",
    "* Scaling Out\n",
    "* Data in Situ with Colossus and Jupiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap03.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap04.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap05.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data in Situ with Colossus and Jupiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap06.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting Data\n",
    "* Reverse Engineering a Web Form\n",
    "* Dataset Download\n",
    "* Exploration and Cleanup\n",
    "* Uploading Data to Google Cloud Storage   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap07.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Engineering a Web Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap08.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap09.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap12.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap13.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration and Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading Data to Google Cloud Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고자료\n",
    "구글 클라우드 스토리지\n",
    "* https://cloud.google.com/storage/\n",
    "* http://jybaek.tistory.com/642\n",
    "\n",
    "#### 생성\n",
    "1. 구글 클라우드 스토리지 콘솔로 이동\n",
    "    * https://console.cloud.google.com/storage/\n",
    "\n",
    "\n",
    "2. 최초 버킷 생성\n",
    "<img src=\"figures/storage_bucket.png\">\n",
    "\n",
    "3. 다음 형태로 콘솔에서 gsutils를 이용해 명령어들을 사용할 수 있다.\n",
    "    * 조회 \n",
    "```shell\n",
    "gsutil ls -a gs://[BUCKET_NAME]\n",
    "```\n",
    "    * 업로드\n",
    "```shell    \n",
    "gsutil -m cp *.csv gs://cloud-training-demos-ml/flights/raw/’\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls gs://[BUCKET_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ds-on-gcp_cloudpsy_ms/43563921_1814266975383729_223249561072697344_n.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://ds-on-gcp_cloudpsy_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 브라우저로 파일 하나 올려보기 (그리고 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls gs://[BUCKET_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 콘솔로 올려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling Monthly Downloads\n",
    "* Ingesting in Python\n",
    "* Flask Web App\n",
    "* Running on App Engine\n",
    "* Securing the URL\n",
    "* Scheduling a Cron Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습 2 - Google App Engine을 이용해 주기적으로 데이터를 가져와서 스토리지에 저장하도록 Cron 서비스에 등록하기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Cloud Shell로 이동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://console.cloud.google.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to the <b>02_ingest/monthlyupdate</b> folder in the repo.<br><br>\n",
    "\n",
    "2. Initialize a default App Engine application in your project by running <b>./init_appengine.sh</b>.<br><br>\n",
    "\n",
    "3. Open the file <b>app.yaml</b> and change the <b>CLOUD_STORAGE_BUCKET</b> to reflect the name of your bucket.<br><br>\n",
    "\n",
    "4. Run <b>./deploy.sh</b> to deploy the Cron service app. This will take 5 to 10 minutes.\n",
    "\n",
    "5. Visit the Google Cloud Platform web console and navigate to the App Engine section. \n",
    "    * You should see two services: \n",
    "        - one the default (which is just a Hello World application) and \n",
    "        - the other is the flights service.<br><br>\n",
    "        \n",
    "6. Click the <b>flights</b> service, follow the link to ingest the data, and you’ll find that your access is forbidden—the ingest capability is available only to the Cron service (or from the Google Cloud Platform web console by clicking the “Run now” button in the task queues section of App Engine). If you click <b>“Run now,”</b> a few minutes later, you’ll see the next month’s data show up in the storage bucket.<br><br>\n",
    "\n",
    "7. Stop the flights application—you won’t need it any further.<br><br>\n",
    "\n",
    "8. Because software changes, an up-to-date list of the preceding steps is available in the course repository in <b>02_ingest/README.md</b>. This is true for all the following chapters.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download data from the BTS website to a local file.<br><br>\n",
    "\n",
    "2. Unzip the downloaded ZIP file and extract the CSV file it contains.<br><br>\n",
    "\n",
    "3. Remove quotes and the trailing comma from the CSV file.<br><br>\n",
    "\n",
    "4. Upload the CSV file to Google Cloud Storage.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.yaml          cron_testing.yaml \u001b[31mingest_flights.py\u001b[m\u001b[m \u001b[31minit_appengine.sh\u001b[m\u001b[m\r\n",
      "cron.yaml         \u001b[31mdeploy.sh\u001b[m\u001b[m         \u001b[31mingestapp.py\u001b[m\u001b[m      requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data-science-on-gcp/02_ingest/monthlyupdate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data-science-on-gcp/02_ingest/monthlyupdate/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.yaml           cron_testing.yaml  \u001b[31mingest_flights.py\u001b[m\u001b[m* \u001b[31minit_appengine.sh\u001b[m\u001b[m*\r\n",
      "cron.yaml          \u001b[31mdeploy.sh\u001b[m\u001b[m*         \u001b[31mingestapp.py\u001b[m\u001b[m*      requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\r\n",
      "\r\n",
      "# Copyright 2016 Google Inc.\r\n",
      "#\r\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
      "# you may not use this file except in compliance with the License.\r\n",
      "# You may obtain a copy of the License at\r\n",
      "#\r\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\r\n",
      "#\r\n",
      "# Unless required by applicable law or agreed to in writing, software\r\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
      "# See the License for the specific language governing permissions and\r\n",
      "# limitations under the License.\r\n",
      "\r\n",
      "import os\r\n",
      "import shutil\r\n",
      "import logging\r\n",
      "import os.path\r\n",
      "import zipfile\r\n",
      "import datetime\r\n",
      "import tempfile\r\n",
      "from urllib2 import urlopen\r\n",
      "from google.cloud import storage\r\n",
      "from google.cloud.storage import Blob\r\n",
      "\r\n",
      "def download(YEAR, MONTH, destdir):\r\n",
      "   '''\r\n",
      "     Downloads on-time performance data and returns local filename\r\n",
      "     YEAR e.g.'2015'\r\n",
      "     MONTH e.g. '01 for January\r\n",
      "   '''\r\n",
      "   logging.info('Requesting data for {}-{}-*'.format(YEAR, MONTH))\r\n",
      "\r\n",
      "   PARAMS=\"UserTableName=On_Time_Performance&DBShortName=&RawDataTable=T_ONTIME&sqlstr=+SELECT+FL_DATE%2CUNIQUE_CARRIER%2CAIRLINE_ID%2CCARRIER%2CFL_NUM%2CORIGIN_AIRPORT_ID%2CORIGIN_AIRPORT_SEQ_ID%2CORIGIN_CITY_MARKET_ID%2CORIGIN%2CDEST_AIRPORT_ID%2CDEST_AIRPORT_SEQ_ID%2CDEST_CITY_MARKET_ID%2CDEST%2CCRS_DEP_TIME%2CDEP_TIME%2CDEP_DELAY%2CTAXI_OUT%2CWHEELS_OFF%2CWHEELS_ON%2CTAXI_IN%2CCRS_ARR_TIME%2CARR_TIME%2CARR_DELAY%2CCANCELLED%2CCANCELLATION_CODE%2CDIVERTED%2CDISTANCE+FROM++T_ONTIME+WHERE+Month+%3D{1}+AND+YEAR%3D{0}&varlist=FL_DATE%2CUNIQUE_CARRIER%2CAIRLINE_ID%2CCARRIER%2CFL_NUM%2CORIGIN_AIRPORT_ID%2CORIGIN_AIRPORT_SEQ_ID%2CORIGIN_CITY_MARKET_ID%2CORIGIN%2CDEST_AIRPORT_ID%2CDEST_AIRPORT_SEQ_ID%2CDEST_CITY_MARKET_ID%2CDEST%2CCRS_DEP_TIME%2CDEP_TIME%2CDEP_DELAY%2CTAXI_OUT%2CWHEELS_OFF%2CWHEELS_ON%2CTAXI_IN%2CCRS_ARR_TIME%2CARR_TIME%2CARR_DELAY%2CCANCELLED%2CCANCELLATION_CODE%2CDIVERTED%2CDISTANCE&grouplist=&suml=&sumRegion=&filter1=title%3D&filter2=title%3D&geo=All%A0&time=March&timename=Month&GEOGRAPHY=All&XYEAR={0}&FREQUENCY=3&VarDesc=Year&VarType=Num&VarDesc=Quarter&VarType=Num&VarDesc=Month&VarType=Num&VarDesc=DayofMonth&VarType=Num&VarDesc=DayOfWeek&VarType=Num&VarName=FL_DATE&VarDesc=FlightDate&VarType=Char&VarName=UNIQUE_CARRIER&VarDesc=UniqueCarrier&VarType=Char&VarName=AIRLINE_ID&VarDesc=AirlineID&VarType=Num&VarName=CARRIER&VarDesc=Carrier&VarType=Char&VarDesc=TailNum&VarType=Char&VarName=FL_NUM&VarDesc=FlightNum&VarType=Char&VarName=ORIGIN_AIRPORT_ID&VarDesc=OriginAirportID&VarType=Num&VarName=ORIGIN_AIRPORT_SEQ_ID&VarDesc=OriginAirportSeqID&VarType=Num&VarName=ORIGIN_CITY_MARKET_ID&VarDesc=OriginCityMarketID&VarType=Num&VarName=ORIGIN&VarDesc=Origin&VarType=Char&VarDesc=OriginCityName&VarType=Char&VarDesc=OriginState&VarType=Char&VarDesc=OriginStateFips&VarType=Char&VarDesc=OriginStateName&VarType=Char&VarDesc=OriginWac&VarType=Num&VarName=DEST_AIRPORT_ID&VarDesc=DestAirportID&VarType=Num&VarName=DEST_AIRPORT_SEQ_ID&VarDesc=DestAirportSeqID&VarType=Num&VarName=DEST_CITY_MARKET_ID&VarDesc=DestCityMarketID&VarType=Num&VarName=DEST&VarDesc=Dest&VarType=Char&VarDesc=DestCityName&VarType=Char&VarDesc=DestState&VarType=Char&VarDesc=DestStateFips&VarType=Char&VarDesc=DestStateName&VarType=Char&VarDesc=DestWac&VarType=Num&VarName=CRS_DEP_TIME&VarDesc=CRSDepTime&VarType=Char&VarName=DEP_TIME&VarDesc=DepTime&VarType=Char&VarName=DEP_DELAY&VarDesc=DepDelay&VarType=Num&VarDesc=DepDelayMinutes&VarType=Num&VarDesc=DepDel15&VarType=Num&VarDesc=DepartureDelayGroups&VarType=Num&VarDesc=DepTimeBlk&VarType=Char&VarName=TAXI_OUT&VarDesc=TaxiOut&VarType=Num&VarName=WHEELS_OFF&VarDesc=WheelsOff&VarType=Char&VarName=WHEELS_ON&VarDesc=WheelsOn&VarType=Char&VarName=TAXI_IN&VarDesc=TaxiIn&VarType=Num&VarName=CRS_ARR_TIME&VarDesc=CRSArrTime&VarType=Char&VarName=ARR_TIME&VarDesc=ArrTime&VarType=Char&VarName=ARR_DELAY&VarDesc=ArrDelay&VarType=Num&VarDesc=ArrDelayMinutes&VarType=Num&VarDesc=ArrDel15&VarType=Num&VarDesc=ArrivalDelayGroups&VarType=Num&VarDesc=ArrTimeBlk&VarType=Char&VarName=CANCELLED&VarDesc=Cancelled&VarType=Num&VarName=CANCELLATION_CODE&VarDesc=CancellationCode&VarType=Char&VarName=DIVERTED&VarDesc=Diverted&VarType=Num&VarDesc=CRSElapsedTime&VarType=Num&VarDesc=ActualElapsedTime&VarType=Num&VarDesc=AirTime&VarType=Num&VarDesc=Flights&VarType=Num&VarName=DISTANCE&VarDesc=Distance&VarType=Num&VarDesc=DistanceGroup&VarType=Num&VarDesc=CarrierDelay&VarType=Num&VarDesc=WeatherDelay&VarType=Num&VarDesc=NASDelay&VarType=Num&VarDesc=SecurityDelay&VarType=Num&VarDesc=LateAircraftDelay&VarType=Num&VarDesc=FirstDepTime&VarType=Char&VarDesc=TotalAddGTime&VarType=Num&VarDesc=LongestAddGTime&VarType=Num&VarDesc=DivAirportLandings&VarType=Num&VarDesc=DivReachedDest&VarType=Num&VarDesc=DivActualElapsedTime&VarType=Num&VarDesc=DivArrDelay&VarType=Num&VarDesc=DivDistance&VarType=Num&VarDesc=Div1Airport&VarType=Char&VarDesc=Div1AirportID&VarType=Num&VarDesc=Div1AirportSeqID&VarType=Num&VarDesc=Div1WheelsOn&VarType=Char&VarDesc=Div1TotalGTime&VarType=Num&VarDesc=Div1LongestGTime&VarType=Num&VarDesc=Div1WheelsOff&VarType=Char&VarDesc=Div1TailNum&VarType=Char&VarDesc=Div2Airport&VarType=Char&VarDesc=Div2AirportID&VarType=Num&VarDesc=Div2AirportSeqID&VarType=Num&VarDesc=Div2WheelsOn&VarType=Char&VarDesc=Div2TotalGTime&VarType=Num&VarDesc=Div2LongestGTime&VarType=Num&VarDesc=Div2WheelsOff&VarType=Char&VarDesc=Div2TailNum&VarType=Char&VarDesc=Div3Airport&VarType=Char&VarDesc=Div3AirportID&VarType=Num&VarDesc=Div3AirportSeqID&VarType=Num&VarDesc=Div3WheelsOn&VarType=Char&VarDesc=Div3TotalGTime&VarType=Num&VarDesc=Div3LongestGTime&VarType=Num&VarDesc=Div3WheelsOff&VarType=Char&VarDesc=Div3TailNum&VarType=Char&VarDesc=Div4Airport&VarType=Char&VarDesc=Div4AirportID&VarType=Num&VarDesc=Div4AirportSeqID&VarType=Num&VarDesc=Div4WheelsOn&VarType=Char&VarDesc=Div4TotalGTime&VarType=Num&VarDesc=Div4LongestGTime&VarType=Num&VarDesc=Div4WheelsOff&VarType=Char&VarDesc=Div4TailNum&VarType=Char&VarDesc=Div5Airport&VarType=Char&VarDesc=Div5AirportID&VarType=Num&VarDesc=Div5AirportSeqID&VarType=Num&VarDesc=Div5WheelsOn&VarType=Char&VarDesc=Div5TotalGTime&VarType=Num&VarDesc=Div5LongestGTime&VarType=Num&VarDesc=Div5WheelsOff&VarType=Char&VarDesc=Div5TailNum&VarType=Char\".format(YEAR, MONTH)\r\n",
      "\r\n",
      "   url='https://www.transtats.bts.gov/DownLoad_Table.asp?Table_ID=236&Has_Group=3&Is_Zipped=0'\r\n",
      "   filename = os.path.join(destdir, \"{}{}.zip\".format(YEAR, MONTH))\r\n",
      "   with open(filename, \"wb\") as fp:\r\n",
      "     response = urlopen(url, PARAMS)\r\n",
      "     fp.write(response.read())\r\n",
      "   logging.debug(\"{} saved\".format(filename))\r\n",
      "   return filename\r\n",
      "\r\n",
      "def zip_to_csv(filename, destdir):\r\n",
      "   zip_ref = zipfile.ZipFile(filename, 'r')\r\n",
      "   cwd = os.getcwd()\r\n",
      "   os.chdir(destdir)\r\n",
      "   zip_ref.extractall()\r\n",
      "   os.chdir(cwd)\r\n",
      "   csvfile = os.path.join(destdir, zip_ref.namelist()[0])\r\n",
      "   zip_ref.close()\r\n",
      "   logging.info(\"Extracted {}\".format(csvfile))\r\n",
      "   return csvfile\r\n",
      "\r\n",
      "\r\n",
      "class DataUnavailable(Exception):\r\n",
      "   def __init__(self, message):\r\n",
      "      self.message = message\r\n",
      "\r\n",
      "class UnexpectedFormat(Exception):\r\n",
      "   def __init__(self, message):\r\n",
      "      self.message = message\r\n",
      "\r\n",
      "def verify_ingest(csvfile):\r\n",
      "   expected_header = 'FL_DATE,UNIQUE_CARRIER,AIRLINE_ID,CARRIER,FL_NUM,ORIGIN_AIRPORT_ID,ORIGIN_AIRPORT_SEQ_ID,ORIGIN_CITY_MARKET_ID,ORIGIN,DEST_AIRPORT_ID,DEST_AIRPORT_SEQ_ID,DEST_CITY_MARKET_ID,DEST,CRS_DEP_TIME,DEP_TIME,DEP_DELAY,TAXI_OUT,WHEELS_OFF,WHEELS_ON,TAXI_IN,CRS_ARR_TIME,ARR_TIME,ARR_DELAY,CANCELLED,CANCELLATION_CODE,DIVERTED,DISTANCE'\r\n",
      "\r\n",
      "   with open(csvfile, 'r') as csvfp:\r\n",
      "      firstline = csvfp.readline().strip()\r\n",
      "      if (firstline != expected_header):\r\n",
      "         os.remove(csvfile)\r\n",
      "         msg = 'Got header={}, but expected={}'.format(\r\n",
      "                             firstline, expected_header)\r\n",
      "         logging.error(msg)\r\n",
      "         raise UnexpectedFormat(msg)\r\n",
      "\r\n",
      "      if next(csvfp, None) == None:\r\n",
      "         os.remove(csvfile)\r\n",
      "         msg = ('Received a file from BTS that has only the header and no content')\r\n",
      "         raise DataUnavailable(msg)\r\n",
      "\r\n",
      "\r\n",
      "def remove_quotes_comma(csvfile, year, month):\r\n",
      " '''\r\n",
      "     returns output_csv_file or raises DataUnavailable exception\r\n",
      " '''\r\n",
      " try:\r\n",
      "   outfile = os.path.join(os.path.dirname(csvfile),\r\n",
      "                          '{}{}.csv'.format(year, month))\r\n",
      "   with open(csvfile, 'r') as infp:\r\n",
      "     with open(outfile, 'w') as outfp:\r\n",
      "        for line in infp:\r\n",
      "           outline = line.rstrip().rstrip(',').translate(None, '\"')\r\n",
      "           outfp.write(outline)\r\n",
      "           outfp.write('\\n')\r\n",
      "   logging.debug('Ingested {} ...'.format(outfile))\r\n",
      "   return outfile\r\n",
      " finally:\r\n",
      "   logging.debug(\"... removing {}\".format(csvfile))\r\n",
      "   os.remove(csvfile)\r\n",
      "\r\n",
      "def upload(csvfile, bucketname, blobname):\r\n",
      "   client = storage.Client()\r\n",
      "   bucket = client.get_bucket(bucketname)\r\n",
      "   blob = Blob(blobname, bucket)\r\n",
      "   blob.upload_from_filename(csvfile)\r\n",
      "   gcslocation = 'gs://{}/{}'.format(bucketname, blobname)\r\n",
      "   logging.info('Uploaded {} ...'.format(gcslocation))\r\n",
      "   return gcslocation\r\n",
      "\r\n",
      "def ingest(year, month, bucket):\r\n",
      "   '''\r\n",
      "   ingest flights data from BTS website to Google Cloud Storage\r\n",
      "   return cloud-storage-blob-name on success.\r\n",
      "   raises DataUnavailable if this data is not on BTS website\r\n",
      "   '''\r\n",
      "   tempdir = tempfile.mkdtemp(prefix='ingest_flights')\r\n",
      "   try:\r\n",
      "      zipfile = download(year, month, tempdir)\r\n",
      "      bts_csv = zip_to_csv(zipfile, tempdir)\r\n",
      "      csvfile = remove_quotes_comma(bts_csv, year, month)\r\n",
      "      verify_ingest(csvfile)\r\n",
      "      gcsloc = 'flights/raw/{}'.format(os.path.basename(csvfile))\r\n",
      "      return upload(csvfile, bucket, gcsloc)\r\n",
      "   finally:\r\n",
      "      logging.debug('Cleaning up by removing {}'.format(tempdir))\r\n",
      "      shutil.rmtree(tempdir)\r\n",
      "\r\n",
      "def next_month(bucketname):\r\n",
      "   '''\r\n",
      "     Finds which months are on GCS, and returns next year,month to download\r\n",
      "   '''\r\n",
      "   client = storage.Client()\r\n",
      "   bucket = client.get_bucket(bucketname)\r\n",
      "   blobs  = list(bucket.list_blobs(prefix='flights/raw/'))\r\n",
      "   files = [blob.name for blob in blobs if 'csv' in blob.name] # csv files only\r\n",
      "   lastfile = os.path.basename(files[-1])\r\n",
      "   logging.debug('The latest file on GCS is {}'.format(lastfile))\r\n",
      "   year = lastfile[:4]\r\n",
      "   month = lastfile[4:6]\r\n",
      "   return compute_next_month(year, month)\r\n",
      "\r\n",
      "def compute_next_month(year, month):\r\n",
      "   dt = datetime.datetime(int(year), int(month), 15) # 15th of month\r\n",
      "   dt = dt + datetime.timedelta(30) # will always go to next month\r\n",
      "   logging.debug('The next month is {}'.format(dt))\r\n",
      "   return '{}'.format(dt.year), '{:02d}'.format(dt.month)\r\n",
      "  \r\n",
      "if __name__ == '__main__':\r\n",
      "   import argparse\r\n",
      "   parser = argparse.ArgumentParser(description='ingest flights data from BTS website to Google Cloud Storage')\r\n",
      "   parser.add_argument('--bucket', help='GCS bucket to upload data to', required=True)\r\n",
      "   parser.add_argument('--year', help='Example: 2015.  If not provided, defaults to getting next month')\r\n",
      "   parser.add_argument('--month', help='Specify 01 for January. If not provided, defaults to getting next month')\r\n",
      "\r\n",
      "   try:\r\n",
      "      logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.INFO)\r\n",
      "      args = parser.parse_args()\r\n",
      "      if args.year is None or args.month is None:\r\n",
      "         year, month = next_month(args.bucket)\r\n",
      "      else:\r\n",
      "         year = args.year\r\n",
      "         month = args.month\r\n",
      "      logging.debug('Ingesting year={} month={}'.format(year, month))\r\n",
      "      gcsfile = ingest(year, month, args.bucket)\r\n",
      "      logging.info('Success ... ingested to {}'.format(gcsfile))\r\n",
      "   except DataUnavailable as e:\r\n",
      "      logging.info('Try again later: {}'.format(e.message))\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "%cat ingest_flights.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flask Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.yaml           cron_testing.yaml  \u001b[31mingest_flights.py\u001b[m\u001b[m* \u001b[31minit_appengine.sh\u001b[m\u001b[m*\r\n",
      "cron.yaml          \u001b[31mdeploy.sh\u001b[m\u001b[m*         \u001b[31mingestapp.py\u001b[m\u001b[m*      requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\r\n",
      "# Copyright 2016 Google Inc.\r\n",
      "#\r\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
      "# you may not use this file except in compliance with the License.\r\n",
      "# You may obtain a copy of the License at\r\n",
      "#\r\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\r\n",
      "#\r\n",
      "# Unless required by applicable law or agreed to in writing, software\r\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
      "# See the License for the specific language governing permissions and\r\n",
      "# limitations under the License.\r\n",
      "\r\n",
      "# [START app]\r\n",
      "import os\r\n",
      "import logging\r\n",
      "import ingest_flights\r\n",
      "\r\n",
      "import flask\r\n",
      "\r\n",
      "# [start config]\r\n",
      "app = flask.Flask(__name__)\r\n",
      "# Configure this environment variable via app.yaml\r\n",
      "CLOUD_STORAGE_BUCKET = os.environ['CLOUD_STORAGE_BUCKET']\r\n",
      "#\r\n",
      "logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.INFO)\r\n",
      "# [end config]\r\n",
      "\r\n",
      "@app.route('/')\r\n",
      "def welcome():\r\n",
      "         return '<html><a href=\"ingest\">ingest next month</a> flight data</html>'\r\n",
      "\r\n",
      "@app.route('/ingest')\r\n",
      "def ingest_next_month():\r\n",
      "    try:\r\n",
      "         # verify that this is a cron job request\r\n",
      "         is_cron = flask.request.headers['X-Appengine-Cron']\r\n",
      "         logging.info('Received cron request {}'.format(is_cron))\r\n",
      "\r\n",
      "         # next month\r\n",
      "         bucket = CLOUD_STORAGE_BUCKET\r\n",
      "         year, month = ingest_flights.next_month(bucket)\r\n",
      "         status = 'scheduling ingest of year={} month={}'.format(year, month)\r\n",
      "         logging.info(status)\r\n",
      "\r\n",
      "         # ingest ...\r\n",
      "         gcsfile = ingest_flights.ingest(year, month, bucket)\r\n",
      "         status = 'successfully ingested={}'.format(gcsfile)\r\n",
      "         logging.info(status)\r\n",
      "\r\n",
      "    except ingest_flights.DataUnavailable:\r\n",
      "         status = 'File for {}-{} not available yet ...'.format(year, month)\r\n",
      "         logging.info(status)\r\n",
      "\r\n",
      "    except KeyError as e:\r\n",
      "         status = '<html>Sorry, this capability is accessible only by the Cron service, but I got a KeyError for {} -- try invoking it from <a href=\"{}\"> the GCP console / AppEngine / taskqueues </a></html>'.format(e, 'http://console.cloud.google.com/appengine/taskqueues?tab=CRON')\r\n",
      "         logging.info('Rejected non-Cron request')\r\n",
      "\r\n",
      "    return status\r\n",
      "\r\n",
      "@app.errorhandler(500)\r\n",
      "def server_error(e):\r\n",
      "    logging.exception('An error occurred during a request.')\r\n",
      "    return \"\"\"\r\n",
      "    An internal error occurred: <pre>{}</pre>\r\n",
      "    See logs for full stacktrace.\r\n",
      "    \"\"\".format(e), 500\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    # This is used when running locally. Gunicorn is used to run the\r\n",
      "    # application on Google App Engine. See entrypoint in app.yaml.\r\n",
      "    app.run(host='127.0.0.1', port=8080, debug=True)\r\n",
      "# [END app]\r\n"
     ]
    }
   ],
   "source": [
    "%cat ingestapp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on App Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.yaml           cron_testing.yaml  \u001b[31mingest_flights.py\u001b[m\u001b[m* \u001b[31minit_appengine.sh\u001b[m\u001b[m*\r\n",
      "cron.yaml          \u001b[31mdeploy.sh\u001b[m\u001b[m*         \u001b[31mingestapp.py\u001b[m\u001b[m*      requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: python\r\n",
      "env: flex\r\n",
      "entrypoint: gunicorn -b :$PORT ingestapp:app\r\n",
      "service: flights\r\n",
      "manual_scaling:\r\n",
      "  instances: 1\r\n",
      "\r\n",
      "#[START env]\r\n",
      "env_variables:\r\n",
      "    CLOUD_STORAGE_BUCKET: cloud-training-demos-ml\r\n",
      "#[END env]\r\n",
      "\r\n",
      "handlers:\r\n",
      "- url: /ingest\r\n",
      "  script: ingestapp.app\r\n",
      "\r\n",
      "- url: /.*\r\n",
      "  script: ingestapp.app\r\n"
     ]
    }
   ],
   "source": [
    "%cat app.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Securing the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.yaml           cron_testing.yaml  \u001b[31mingest_flights.py\u001b[m\u001b[m* \u001b[31minit_appengine.sh\u001b[m\u001b[m*\r\n",
      "cron.yaml          \u001b[31mdeploy.sh\u001b[m\u001b[m*         \u001b[31mingestapp.py\u001b[m\u001b[m*      requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\r\n",
      "# Copyright 2016 Google Inc.\r\n",
      "#\r\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
      "# you may not use this file except in compliance with the License.\r\n",
      "# You may obtain a copy of the License at\r\n",
      "#\r\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\r\n",
      "#\r\n",
      "# Unless required by applicable law or agreed to in writing, software\r\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
      "# See the License for the specific language governing permissions and\r\n",
      "# limitations under the License.\r\n",
      "\r\n",
      "# [START app]\r\n",
      "import os\r\n",
      "import logging\r\n",
      "import ingest_flights\r\n",
      "\r\n",
      "import flask\r\n",
      "\r\n",
      "# [start config]\r\n",
      "app = flask.Flask(__name__)\r\n",
      "# Configure this environment variable via app.yaml\r\n",
      "CLOUD_STORAGE_BUCKET = os.environ['CLOUD_STORAGE_BUCKET']\r\n",
      "#\r\n",
      "logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.INFO)\r\n",
      "# [end config]\r\n",
      "\r\n",
      "@app.route('/')\r\n",
      "def welcome():\r\n",
      "         return '<html><a href=\"ingest\">ingest next month</a> flight data</html>'\r\n",
      "\r\n",
      "@app.route('/ingest')\r\n",
      "def ingest_next_month():\r\n",
      "    try:\r\n",
      "         # verify that this is a cron job request\r\n",
      "         is_cron = flask.request.headers['X-Appengine-Cron']\r\n",
      "         logging.info('Received cron request {}'.format(is_cron))\r\n",
      "\r\n",
      "         # next month\r\n",
      "         bucket = CLOUD_STORAGE_BUCKET\r\n",
      "         year, month = ingest_flights.next_month(bucket)\r\n",
      "         status = 'scheduling ingest of year={} month={}'.format(year, month)\r\n",
      "         logging.info(status)\r\n",
      "\r\n",
      "         # ingest ...\r\n",
      "         gcsfile = ingest_flights.ingest(year, month, bucket)\r\n",
      "         status = 'successfully ingested={}'.format(gcsfile)\r\n",
      "         logging.info(status)\r\n",
      "\r\n",
      "    except ingest_flights.DataUnavailable:\r\n",
      "         status = 'File for {}-{} not available yet ...'.format(year, month)\r\n",
      "         logging.info(status)\r\n",
      "\r\n",
      "    except KeyError as e:\r\n",
      "         status = '<html>Sorry, this capability is accessible only by the Cron service, but I got a KeyError for {} -- try invoking it from <a href=\"{}\"> the GCP console / AppEngine / taskqueues </a></html>'.format(e, 'http://console.cloud.google.com/appengine/taskqueues?tab=CRON')\r\n",
      "         logging.info('Rejected non-Cron request')\r\n",
      "\r\n",
      "    return status\r\n",
      "\r\n",
      "@app.errorhandler(500)\r\n",
      "def server_error(e):\r\n",
      "    logging.exception('An error occurred during a request.')\r\n",
      "    return \"\"\"\r\n",
      "    An internal error occurred: <pre>{}</pre>\r\n",
      "    See logs for full stacktrace.\r\n",
      "    \"\"\".format(e), 500\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    # This is used when running locally. Gunicorn is used to run the\r\n",
      "    # application on Google App Engine. See entrypoint in app.yaml.\r\n",
      "    app.run(host='127.0.0.1', port=8080, debug=True)\r\n",
      "# [END app]\r\n"
     ]
    }
   ],
   "source": [
    "%cat ingestapp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 앱엔진의 cron job이 아닌 방식으로 요청이 들어오면 에러를 낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@app.route('/ingest')\n",
    "def ingest_next_month():\n",
    "    try:\n",
    "         # verify that this is a cron job request\n",
    "         is_cron = flask.request.headers['X-Appengine-Cron']\n",
    "         logging.info('Received cron request {}'.format(is_cron))\n",
    "\n",
    "         # next month\n",
    "         bucket = CLOUD_STORAGE_BUCKET\n",
    "         year, month = ingest_flights.next_month(bucket)\n",
    "         status = 'scheduling ingest of year={} month={}'.format(year, month)\n",
    "         logging.info(status)\n",
    "\n",
    "         # ingest ...\n",
    "         gcsfile = ingest_flights.ingest(year, month, bucket)\n",
    "         status = 'successfully ingested={}'.format(gcsfile)\n",
    "         logging.info(status)\n",
    "\n",
    "    except ingest_flights.DataUnavailable:\n",
    "         status = 'File for {}-{} not available yet ...'.format(year, month)\n",
    "         logging.info(status)\n",
    "\n",
    "    except KeyError as e:\n",
    "         status = '<html>Sorry, this capability is accessible only by the Cron service, but I got a KeyError for {} -- try invoking it from <a href=\"{}\"> the GCP console / AppEngine / taskqueues </a></html>'.format(e, 'http://console.cloud.google.com/appengine/taskqueues?tab=CRON')\n",
    "         logging.info('Rejected non-Cron request')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling a Cron Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cron:\r\n",
      "- description : ingest monthly flight data\r\n",
      "  url : /ingest\r\n",
      "  schedule: 8 of month 10:00\r\n",
      "  timezone: US/Eastern\r\n",
      "  target: flights\r\n"
     ]
    }
   ],
   "source": [
    "%cat cron.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "* [1] Data Science on the Google Cloud Platform: Implementing End-to-End Real-Time Data Pipelines: From Ingest to Machine Learning - https://www.amazon.com/Data-Science-Google-Cloud-Platform/dp/1491974567\n",
    "* [2] Book github - https://github.com/GoogleCloudPlatform/data-science-on-gcp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
